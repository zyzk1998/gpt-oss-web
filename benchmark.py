import requests
import time
import json
import random
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import os

# ================= é…ç½®åŒºåŸŸ =================
API_URL = "http://localhost:8082/api/chat"
TOTAL_REQUESTS_PER_CATEGORY = 20  # âš ï¸ å»ºè®®å…ˆè®¾ä¸º 20 è¿›è¡Œæµ‹è¯•ï¼Œç¡®è®¤æ— è¯¯åå†æ”¹ä¸º 100
CONCURRENCY = 1  # âš ï¸ å¼ºçƒˆå»ºè®®è®¾ä¸º 1ã€‚32B æ¨¡å‹æ˜¾å­˜å ç”¨é«˜ï¼Œå¹¶å‘ä¼šå¯¼è‡´ OOM æˆ–ææ…¢
OUTPUT_DIR = "./benchmark_reports"

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ================= æµ‹è¯•æ•°æ®é›† (Prompt Pools) =================
PROMPT_POOLS = {
    "Biomedical_QA": [
        "è§£é‡Šä¸€ä¸‹ P53 åŸºå› åœ¨ç™Œç—‡ä¸­çš„ä½œç”¨",
        "ä»€ä¹ˆæ˜¯ä¸­å¿ƒæ³•åˆ™ï¼ˆCentral Dogmaï¼‰ï¼Ÿ",
        "CRISPR-Cas9 çš„å·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
        "çº¿ç²’ä½“ä¸ºä»€ä¹ˆè¢«ç§°ä¸ºç»†èƒçš„åŠ¨åŠ›å·¥å‚ï¼Ÿ",
        "è§£é‡Šå•ç»†èƒæµ‹åºä¸­çš„ Dropout ç°è±¡",
        "ä»€ä¹ˆæ˜¯ T ç»†èƒè€—ç«­ï¼Ÿ",
        "DNA ç”²åŸºåŒ–å¦‚ä½•å½±å“åŸºå› è¡¨è¾¾ï¼Ÿ",
        "ä»‹ç»ä¸€ä¸‹é˜¿å°”èŒ¨æµ·é»˜ç—…çš„ç—…ç†æœºåˆ¶",
        "ä»€ä¹ˆæ˜¯ GWAS ç ”ç©¶ï¼Ÿ",
        "RNA-seq å’Œ scRNA-seq çš„ä¸»è¦åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ"
    ],
    "Bioinfo_Concept": [
        "å¦‚ä½•ä½¿ç”¨ Seurat è¿›è¡Œæ•°æ®å½’ä¸€åŒ–ï¼Ÿ",
        "FastQC æŠ¥å‘Šä¸­çš„ GC Content å¼‚å¸¸è¯´æ˜ä»€ä¹ˆï¼Ÿ",
        "è§£é‡Š PCA é™ç»´åœ¨ç”Ÿä¿¡åˆ†æä¸­çš„æ„ä¹‰",
        "å¦‚ä½•è¿‡æ»¤å•ç»†èƒæ•°æ®ä¸­çš„åŒç»†èƒï¼ˆDoubletsï¼‰ï¼Ÿ",
        "DESeq2 å’Œ edgeR æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯ Batch Effectï¼ˆæ‰¹æ¬¡æ•ˆåº”ï¼‰ï¼Œå¦‚ä½•å»é™¤ï¼Ÿ",
        "å¦‚ä½•è§£è¯»ç«å±±å›¾ï¼ˆVolcano Plotï¼‰ï¼Ÿ",
        "Bam æ–‡ä»¶å’Œ Sam æ–‡ä»¶æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯ UMAPï¼Ÿå®ƒå’Œ t-SNE æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ",
        "å¦‚ä½•è¿›è¡Œ GO å¯Œé›†åˆ†æï¼Ÿ"
    ],
    "General_Chat": [
        "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±",
        "ç»™æˆ‘è®²ä¸ªç¬‘è¯",
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        "å†™ä¸€é¦–å…³äº DNA çš„è¯—",
        "ä½ æ˜¯è°å¼€å‘çš„ï¼Ÿ",
        "1+1ç­‰äºå‡ ï¼Ÿ",
        "å¸®æˆ‘å†™ä¸€å°ç»™å¯¼å¸ˆçš„é‚®ä»¶è‰ç¨¿",
        "æ¨èå‡ æœ¬å¥½ä¹¦",
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        "ç¿»è¯‘è¿™å¥è¯æˆè‹±æ–‡ï¼šç”Ÿä¿¡åˆ†æå¾ˆæœ‰è¶£"
    ],
    "Galaxy_Intent": [
        "åˆ—å‡ºæ‰€æœ‰ Seurat ç›¸å…³çš„å·¥å…·",          # æœŸæœ›: choice æˆ– text
        "æˆ‘è¦åšå•ç»†èƒåˆ†æï¼Œè¯·è§„åˆ’å·¥ä½œæµ",       # æœŸæœ›: workflow_config
        "Run Seurat Create Object",           # æœŸæœ›: tool_config
        "å¸®æˆ‘æŸ¥æ‰¾è¿‡æ»¤ç»†èƒçš„å·¥å…·",              # æœŸæœ›: choice æˆ– tool_config
        "æ‰§è¡Œ Seurat å½’ä¸€åŒ–",                 # æœŸæœ›: tool_config
        "Show me Seurat tools",
        "è§„åˆ’ä¸€ä¸ª Seurat æµç¨‹",               # æœŸæœ›: workflow_config
        "Run PCA",                            # æœŸæœ›: tool_config
        "Find Neighbors tool",
        "Run UMAP visualization"
    ]
}

# ================= æ ¸å¿ƒæµ‹è¯•é€»è¾‘ =================

def send_request(category, prompt, req_id):
    payload = {
        "message": prompt,
        "history": [],
        "uploaded_files": []
    }
    
    start_time = time.time()
    result = {
        "id": req_id,
        "category": category,
        "prompt": prompt,
        "status_code": 0,
        "latency": 0,
        "response_type": "error",
        "thought_len": 0,
        "success": False,
        "error_msg": ""
    }

    try:
        # è®¾ç½®è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´ï¼Œå› ä¸º 32B æ¨¡å‹æ¨ç†è¾ƒæ…¢
        response = requests.post(API_URL, json=payload, timeout=600) 
        end_time = time.time()
        
        result["latency"] = round(end_time - start_time, 2)
        result["status_code"] = response.status_code
        
        if response.status_code == 200:
            data = response.json()
            result["response_type"] = data.get("type", "unknown")
            # ç»Ÿè®¡æ€è€ƒè¿‡ç¨‹çš„é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰ï¼Œåæ˜ æ¨ç†æ·±åº¦
            thought_content = data.get("thought", "")
            result["thought_len"] = len(thought_content) if thought_content else 0
            
            # === æˆåŠŸåˆ¤å®šé€»è¾‘ ===
            if category == "Galaxy_Intent":
                # å¯¹äºå·¥å…·/æµç¨‹æ„å›¾ï¼Œåªè¦è¿”å›äº†ç»“æ„åŒ–é…ç½®æˆ–é€‰æ‹©åˆ—è¡¨ï¼Œå°±ç®—æˆåŠŸ
                if result["response_type"] in ["tool_config", "workflow_config", "choice", "data_selector"]:
                    result["success"] = True
                # å¦‚æœæ˜¯â€œåˆ—å‡ºâ€ï¼Œè¿”å› text ä½†åŒ…å«åˆ—è¡¨å†…å®¹ä¹Ÿç®—å¯¹
                elif result["response_type"] == "text" and ("1." in data.get("reply", "") or "-" in data.get("reply", "")):
                    result["success"] = True
                else:
                    result["success"] = False
            else:
                # å¯¹äºé—®ç­”ç±»ï¼Œåªè¦è¿”å› text ä¸”ä¸ä¸ºç©ºå°±ç®—æˆåŠŸ
                if result["response_type"] == "text" and len(data.get("reply", "")) > 10:
                    result["success"] = True
                else:
                    result["success"] = False
        else:
            result["error_msg"] = f"HTTP {response.status_code}"
            
    except Exception as e:
        result["error_msg"] = str(e)
        result["latency"] = round(time.time() - start_time, 2)
    
    return result

def run_benchmark():
    results = []
    total_tasks = len(PROMPT_POOLS) * TOTAL_REQUESTS_PER_CATEGORY
    
    print(f"\nğŸš€ [GIBH Qwen Galaxy] æ€§èƒ½åŸºå‡†æµ‹è¯•å¯åŠ¨")
    print(f"ğŸ§  æ¨¡å‹: {LLM_MODEL} (32B)")
    print(f"ğŸ“Š æ€»ä»»åŠ¡æ•°: {total_tasks} (æ¯ç±» {TOTAL_REQUESTS_PER_CATEGORY} æ¬¡)")
    print(f"ğŸ–¥ï¸  å¹¶å‘çº¿ç¨‹: {CONCURRENCY}")
    print("-" * 50)
    
    # å‡†å¤‡ä»»åŠ¡é˜Ÿåˆ—
    tasks = []
    req_id = 0
    for category, prompts in PROMPT_POOLS.items():
        for _ in range(TOTAL_REQUESTS_PER_CATEGORY):
            prompt = random.choice(prompts)
            tasks.append((category, prompt, req_id))
            req_id += 1
            
    # è¿›åº¦æ¡
    pbar = tqdm(total=total_tasks, desc="Testing", unit="req")
    
    # çº¿ç¨‹æ± æ‰§è¡Œ
    with ThreadPoolExecutor(max_workers=CONCURRENCY) as executor:
        future_to_req = {executor.submit(send_request, t[0], t[1], t[2]): t for t in tasks}
        
        for future in as_completed(future_to_req):
            res = future.result()
            results.append(res)
            pbar.update(1)
            
            # å®æ—¶é”™è¯¯æ—¥å¿—
            if not res["success"] and res["status_code"] == 200:
                # æ„å›¾è¯†åˆ«å¤±è´¥ï¼ˆæ¯”å¦‚é—®å·¥å…·å´å›äº†é—²èŠï¼‰
                tqdm.write(f"âš ï¸ [Intent Fail] {res['category']} -> Got {res['response_type']} | Prompt: {res['prompt'][:15]}...")
            elif res["status_code"] != 200:
                # ç³»ç»Ÿé”™è¯¯
                tqdm.write(f"âŒ [Sys Error] {res['error_msg']}")

    pbar.close()
    return pd.DataFrame(results)

# ================= å¯è§†åŒ–æŠ¥å‘Šç”Ÿæˆ =================

def generate_report(df):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. ä¿å­˜ CSV
    csv_path = f"{OUTPUT_DIR}/benchmark_{timestamp}.csv"
    df.to_csv(csv_path, index=False)
    print(f"\nğŸ’¾ åŸå§‹æ•°æ®å·²ä¿å­˜: {csv_path}")

    # 2. è®¾ç½®ç»˜å›¾é£æ ¼
    sns.set_theme(style="whitegrid")
    # å°è¯•è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œå¦‚æœæ²¡æœ‰åˆ™å›é€€åˆ°è‹±æ–‡
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False

    fig = plt.figure(figsize=(20, 12))
    fig.suptitle(f'GIBH Qwen Galaxy (32B) Performance Benchmark', fontsize=20, y=0.95)

    # --- å›¾ 1: å¹³å‡å»¶è¿Ÿ (Bar Plot) ---
    ax1 = plt.subplot(2, 2, 1)
    sns.barplot(data=df, x="category", y="latency", hue="category", errorbar="sd", ax=ax1, palette="viridis")
    ax1.set_title("Average Latency (seconds)", fontsize=14)
    ax1.set_xlabel("")
    ax1.set_ylabel("Time (s)")
    for container in ax1.containers:
        ax1.bar_label(container, fmt='%.1f')

    # --- å›¾ 2: å»¶è¿Ÿåˆ†å¸ƒ (Box Plot) ---
    ax2 = plt.subplot(2, 2, 2)
    sns.boxplot(data=df, x="category", y="latency", hue="category", ax=ax2, palette="pastel")
    ax2.set_title("Latency Distribution (Stability)", fontsize=14)
    ax2.set_xlabel("")
    ax2.set_ylabel("Time (s)")

    # --- å›¾ 3: æˆåŠŸç‡ (Stacked Bar) ---
    ax3 = plt.subplot(2, 2, 3)
    success_counts = df.groupby(['category', 'success']).size().reset_index(name='counts')
    total_counts = df.groupby('category').size().reset_index(name='total')
    success_counts = success_counts.merge(total_counts, on='category')
    success_counts['percentage'] = (success_counts['counts'] / success_counts['total']) * 100
    
    # åªç”»æˆåŠŸçš„éƒ¨åˆ†
    success_only = success_counts[success_counts['success']==True]
    if not success_only.empty:
        sns.barplot(data=success_only, x="category", y="percentage", hue="category", ax=ax3, palette="RdYlGn")
        ax3.set_ylim(0, 110)
        for container in ax3.containers:
            ax3.bar_label(container, fmt='%.1f%%')
    ax3.set_title("Intent Recognition Accuracy (%)", fontsize=14)
    ax3.set_xlabel("")
    ax3.set_ylabel("Success Rate (%)")

    # --- å›¾ 4: æ€è€ƒæ·±åº¦ (Violin Plot) ---
    ax4 = plt.subplot(2, 2, 4)
    sns.violinplot(data=df, x="category", y="thought_len", hue="category", ax=ax4, palette="magma")
    ax4.set_title("Reasoning Depth (Thought Token Length)", fontsize=14)
    ax4.set_xlabel("")
    ax4.set_ylabel("Char Count")

    plt.tight_layout(rect=[0, 0.03, 1, 0.93])
    
    img_path = f"{OUTPUT_DIR}/report_{timestamp}.png"
    plt.savefig(img_path, dpi=300)
    print(f"ğŸ“Š å¯è§†åŒ–æŠ¥è¡¨å·²ç”Ÿæˆ: {img_path}")
    
    # æ‰“å°ç®€æŠ¥
    print("\n" + "="*40)
    print("ğŸ“‹ æµ‹è¯•æ‘˜è¦ (Summary)")
    print("="*40)
    summary = df.groupby("category")[["latency", "success", "thought_len"]].mean()
    summary.columns = ["Avg Latency (s)", "Success Rate", "Avg Thought Len"]
    print(summary.to_string())

if __name__ == "__main__":
    # å¥åº·æ£€æŸ¥
    try:
        print("Checking API health...")
        requests.get("http://localhost:8082", timeout=5)
        print("âœ… API is online.")
    except:
        print("âŒ Error: Cannot connect to http://localhost:8082. Please start app.py first!")
        exit(1)

    # è¿è¡Œæµ‹è¯•
    df_results = run_benchmark()
    
    # ç”ŸæˆæŠ¥å‘Š
    if not df_results.empty:
        generate_report(df_results)
    else:
        print("âŒ No data collected.")
