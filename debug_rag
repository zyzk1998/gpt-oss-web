import os
from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma
from dotenv import load_dotenv

load_dotenv()

# é…ç½®
DB_PATH = "data/chroma_db_bioblend"
EMBED_MODEL = "nomic-embed-text"
OLLAMA_URL = "http://localhost:11434"

def debug_retrieval():
    print(f"ğŸ” æ­£åœ¨åŠ è½½å‘é‡åº“: {DB_PATH} ...")
    if not os.path.exists(DB_PATH):
        print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°å‘é‡åº“æ–‡ä»¶å¤¹ï¼")
        return

    embeddings = OllamaEmbeddings(model=EMBED_MODEL, base_url=OLLAMA_URL)
    vector_db = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)
    
    question = "æŸ¥è¯¢æˆ‘çš„è´¦æˆ·ä¿¡æ¯"
    print(f"\nâ“ æµ‹è¯•æé—®: {question}")
    
    # å…³é”®ï¼šæˆ‘ä»¬æŠŠ k è®¾å¤§ä¸€ç‚¹ï¼Œçœ‹çœ‹æ­£ç¡®ç­”æ¡ˆæ’åœ¨ç¬¬å‡ å
    print("--- æ­£åœ¨æ£€ç´¢å‰ 5 æ¡ç›¸å…³çŸ¥è¯† ---")
    docs = vector_db.similarity_search(question, k=5)
    
    for i, doc in enumerate(docs):
        print(f"\n[ç¬¬ {i+1} å] Score: (Chromaä¸ç›´æ¥è¿”å›åˆ†æ•°)")
        print(f"å†…å®¹æ‘˜è¦: {doc.page_content[:100]}...") # åªæ‰“å°å‰100ä¸ªå­—
        print(f"å…ƒæ•°æ®: {doc.metadata}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬æƒ³è¦çš„é‚£æ¡è§„åˆ™
        if "get_current_user" in doc.page_content:
            print("âœ…âœ…âœ… æ‰¾åˆ°äº†ï¼æ­£ç¡®è§„åˆ™åœ¨è¿™é‡Œï¼")
        else:
            print("âŒ è¿™ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„è§„åˆ™")

if __name__ == "__main__":
    debug_retrieval()
